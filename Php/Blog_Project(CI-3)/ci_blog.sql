-- phpMyAdmin SQL Dump
-- version 5.2.0
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Aug 01, 2022 at 04:10 PM
-- Server version: 10.4.24-MariaDB
-- PHP Version: 8.1.6

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `ci_blog`
--

-- --------------------------------------------------------

--
-- Table structure for table `articles`
--

CREATE TABLE `articles` (
  `id` int(255) NOT NULL,
  `title` varchar(255) NOT NULL,
  `body` text NOT NULL,
  `user_id` int(255) NOT NULL,
  `created_at` varchar(255) NOT NULL,
  `image_path` varchar(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

--
-- Dumping data for table `articles`
--

INSERT INTO `articles` (`id`, `title`, `body`, `user_id`, `created_at`, `image_path`) VALUES
(14, 'What is an article?', 'An article is a word that is used to indicate that a noun is a noun without describing it. For example, in the sentence Nick bought a dog, the article a indicates that the word dog is a noun. Articles can also modify anything that acts as a noun, such as a pronoun or a noun phrase.\r\n\r\nOften, a sentence needs an article before a noun in order to make grammatical sense. For example,\r\n\r\n❌ Incorrect: I have box.\r\n✅ Correct: I have a box.\r\n\r\n❌ Incorrect: She opened door.\r\n✅ Correct: She opened the door.\r\n\r\n❌ Incorrect: French is spoken by French.\r\n✅ Correct: French is spoken by the French', 1, '2022-07-31 12:09:02', ''),
(15, 'Articles in Grammar', 'English Articles (a, an, the)! Learn how to use articles (a, an, the) in English with useful grammar rules, ESL printable worksheets and example sentences. When studying English grammar, you may have come across the article. We are going to take a look at what an article is, how it is used and the rules surrounding it. We are going to do this by taking a look at some examples of articles in use within a sentence, this way we will be able to gain a greater understanding of its function.', 1, '2022-07-31 12:09:02', ''),
(16, 'What is Self-Improvement?', 'Best Self-Improvement Articles to Start With\nSelf-improvement almost always starts with self-awareness and the ability to transform your habits. If you\'re serious about transforming your life and improving yourself, you should start with these two articles:\n\nHow to Stop Lying to Ourselves: A Call for Self-Awareness: If you\'re serious about getting better at something, then one of the first steps is to know—in black-and-white terms—where you stand. You need self-awareness before you can achieve self-improvement.\nForget About Setting Goals. Focus on This Instead: For most of us, the path to self-improvement starts by setting a specific and actionable goal. What I\'m starting to realize, however, is that when it comes to actually getting things done and making progress in the areas that are important to you, there is a much better way to do things. It all comes down to the difference between goals and systems.', 1, '2022-07-31 12:09:02', ''),
(17, 'By Steve Snyder | December 21, 2020', 'This is the latest roundup in our “Best Of” series, spotlighting top highlights from this year’s coverage as well as the most popular articles we’ve published each month. See more of the standouts from across 2020 right here.\r\n\r\nAny student will forever remember 2020 as the year that the classrooms and campuses closed down. As coronavirus cases surged in the spring — and then again in the autumn — educators, families and district leaders did their best to pivot to a socially-distanced Plan B, building a new system of remote instruction overnight in hopes of maintaining learning and community.\r\n\r\nAny education journalist will remember 2020 as the year that all the planned student profiles, school spotlights and policy investigations got thrown out the window as we scrambled to capture and process the disorienting new normal of virtual classrooms. Here at The 74, our top stories from the past nine months were dominated by our reporting in this area, by features that framed the challenges and opportunities of distance learning, that surfaced solutions and innovations that were working for some districts, and that pointed to the bigger questions of how disrupted back-to-back school years may lead to long-term consequences for this generation of students.\r\n\r\nAs we approach the new year, we’re continuing to report on America’s evolving, patchwork education system via our coronavirus education reporting project at The74Million.org/PANDEMIC. With school campuses open in some states and not others, with some families preferring in-person classes or remote learning alternatives, and with some individual classrooms being forced to close in rolling 14-day increments with new coronavirus breakouts, it’s clear that our education system will begin 2021 in a similar state of turmoil. (Get our latest reporting on schools and the pandemic delivered straight to your inbox by signing up for The 74 Newsletter)\r\n\r\nBut with the first vaccines being administered this month, we’re seeing our first glimpse of a light at the end of this chaotic tunnel — hope that the virus will quickly dissipate, that schools will fully reopen, and that we’ll then find a way to help all of America’s 74 million children catch up. Here are our 20 most read and shared articles of the year:', 1, '2022-07-31 12:09:02', ''),
(18, 'Web Pages and Web-Based Applications', 'A web page or web application is required to offer high levels of customization, a very interactive user interface and should be able to perform online transactions and integrate with database systems. PHP ensures all these features are achieved through its three-tiered architecture that works in a linear fashion on browser, server, and database systems. This explains why more than 82% of websites use PHP for server-side programming. Numerous web-based applications and Facebook apps are scripted in PHP too.\r\n\r\nPHP can be used to build both static and dynamic web pages and web-based applications. Developers can manipulate the coding to reuse it in other applications too. Built-in mechanisms like support for user authentication, SQL query builder, CSRF protection, and routing make PHP one of the most in-demand programming languages. Besides being an open-source platform with free licensing, PHP enjoys high popularity among programming languages.   ', 1, '2022-07-31 12:09:02', ''),
(19, 'Cognitive Biases In Software Development', 'A couple of years ago, I started my first job as a programmer. On the first day, I entered the office, sat in my new chair, turned on the computer, checked out a project from the version control system and opened it in IDE. The first-ever piece of the code I saw looked like that:\r\nAs you may already have guessed, this code remained untouched for a couple of years, until the project became obsolete and was archived and longer used. But the thing that bothered me then and still bothers me sometimes is why the person who coded working solution felt not comfortable with it, despite it being the completely normal and working solution. Why on a code review, or when exploring new projects, frameworks, and libraries we sometimes think — it is implemented weirdly, they should’ve done it some other way.\r\n\r\nIn this post, I will try to answer the question: why do we feel weird about technical solutions?\r\n\r\nHumans like patterns. And I am not even talking only about programming or system design right now. Patterns are everywhere in the life of any person. Patterns save us a lot of time by providing a working solution for a familiar task. You don’t recreate the process of brushing your teeth and taking a shower in the morning, as well as you don’t put many thoughts into writing simple CRUD application.\r\n\r\nPatterns of thinking are the main principle of many puzzles and riddles, such as Bat and ball price or Monty Hall Problem.\r\n\r\nPatterns help our brains to do less work and to solve problems quicker. Of course, when you need to do many similar things every day, your brain creates a “cache” of those situations with many predefined actions to do. But there are cases when your subconscious consistently matches an incorrect answer to real-world situations.\r\n\r\nSuch situations are called cognitive biases. And, as in any other professional area, software development is full of specific behavioral patterns. I think we all can remember some stories from our professional experience where we’ve seen this behavior in other people and in ourselves.', 1, '2022-07-31 12:09:02', ''),
(20, 'The New Business of AI (and How It’s Different From Traditional Software)', 'Martin Casado, Matt Bornstein\r\n\r\n\r\n\r\nAt a technical level, artificial intelligence seems to be the future of software. AI is showing remarkable progress on a range of difficult computer science problems, and the job of software developers – who now work with data as much as source code – is changing fundamentally in the process.\r\n\r\nMany AI companies (and investors) are betting that this relationship will extend beyond just technology – that AI businesses will resemble traditional software companies as well. Based on our experience working with AI companies, we’re not so sure.\r\n\r\nWe are huge believers in the power of AI to transform business: We’ve put our money behind that thesis, and we will continue to invest heavily in both applied AI companies and AI infrastructure. However, we have noticed in many cases that AI companies simply don’t have the same economic construction as software businesses. At times, they can even look more like traditional services companies. In particular, many AI companies have:\r\n\r\nLower gross margins due to heavy cloud infrastructure usage and ongoing human support;\r\nScaling challenges due to the thorny problem of edge cases;\r\nWeaker defensive moats due to the commoditization of AI models and challenges with data network effects.\r\nAnecdotally, we have seen a surprisingly consistent pattern in the financial data of AI companies, with gross margins often in the 50-60% range – well below the 60-80%+ benchmark for comparable SaaS businesses. Early-stage private capital can hide these inefficiencies in the short term, especially as some investors push for growth over profitability. It’s not clear, though, that any amount of long-term product or go-to-market (GTM) optimization can completely solve the issue.\r\n\r\n\r\nJust as SaaS ushered in a novel economic model compared to on-premise software, we believe AI is creating an essentially new type of business. So this post walks through some of the ways AI companies differ from traditional software companies and shares some advice on how to address those differences. Our goal is not to be prescriptive but rather help operators and others understand the economics and strategic landscape of AI so they can build enduring companies.\r\n\r\nSoftware + services = AI?\r\nThe beauty of software (including SaaS) is that it can be produced once and sold many times. This property creates a number of compelling business benefits, including recurring revenue streams, high (60-80%+) gross margins, and – in relatively rare cases when network effects or scale effects take hold – superlinear scaling. Software companies also have the potential to build strong defensive moats because they own the intellectual property (typically the code) generated by their work.\r\n\r\nService businesses occupy the other end of the spectrum. Each new project requires dedicated headcount and can be sold exactly once. As a result, revenue tends to be non-recurring, gross margins are lower (30-50%), and scaling is linear at best. Defensibility is more challenging – often based on brand or incumbent account control – because any IP not owned by the customer is unlikely to have broad applicability.\r\n\r\nAI companies appear, increasingly, to combine elements of both software and services.\r\n\r\nMost AI applications look and feel like normal software. They rely on conventional code to perform tasks like interfacing with users, managing data, or integrating with other systems. The heart of the application, though, is a set of trained data models. These models interpret images, transcribe speech, generate natural language, and perform other complex tasks. Maintaining them can feel, at times, more like a services business – requiring significant, customer-specific work and input costs beyond typical support and success functions.\r\n\r\nThis dynamic impacts AI businesses in a number of important ways. We explore several – gross margins, scaling, and defensibility – in the following sections.\r\n\r\nGross Margins, Part 1: Cloud infrastructure is a substantial – and sometimes hidden – cost for AI companies\r\nIn the old days of on-premise software, delivering a product meant stamping out and shipping physical media – the cost of running the software, whether on servers or desktops, was borne by the buyer. Today, with the dominance of SaaS, that cost has been pushed back to the vendor. Most software companies pay big AWS or Azure bills every month – the more demanding the software, the higher the bill.\r\n\r\n\r\nAI, it turns out, is pretty demanding:\r\n\r\nTraining a single AI model can cost hundreds of thousands of dollars (or more) in compute resources. While it’s tempting to treat this as a one-time cost, retraining is increasingly recognized as an ongoing cost, since the data that feeds AI models tends to change over time (a phenomenon known as “data drift”).\r\nModel inference (the process of generating predictions in production) is also more computationally complex than operating traditional software. Executing a long series of matrix multiplications just requires more math than, for example, reading from a database.\r\nAI applications are more likely than traditional software to operate on rich media like images, audio, or video. These types of data consume higher than usual storage resources, are expensive to process, and often suffer from region of interest issues – an application may need to process a large file to find a small, relevant snippet.\r\nWe’ve had AI companies tell us that cloud operations can be more complex and costly than traditional approaches, particularly because there aren’t good tools to scale AI models globally. As a result, some AI companies have to routinely transfer trained models across cloud regions – racking up big ingress and egress costs – to improve reliability, latency, and compliance.\r\nTaken together, these forces contribute to the 25% or more of revenue that AI companies often spend on cloud resources. In extreme cases, startups tackling particularly complex tasks have actually found manual data processing cheaper than executing a trained model.\r\n\r\nHelp is coming in the form of specialized AI processors that can execute computations more efficiently and optimization techniques, such as model compression and cross-compilation, that reduce the number of computations needed.\r\n\r\nBut it’s not clear what the shape of the efficiency curve will look like. In many problem domains, exponentially more processing and data are needed to get incrementally more accuracy. This means – as we’ve noted before – that model complexity is growing at an incredible rate, and it’s unlikely processors will be able to keep up. Moore’s Law is not enough. (For example, the compute resources required to train state-of-the-art AI models has grown over 300,000x since 2012, while the transistor count of NVIDIA GPUs has grown only ~4x!) Distributed computing is a compelling solution to this problem, but it primarily addresses speed – not cost.\r\n\r\nGross Margins, Part 2: Many AI applications rely on “humans in the loop” to function at a high level of accuracy \r\nHuman-in-the-loop systems take two forms, both of which contribute to lower gross margins for many AI startups.\r\n\r\nFirst: training most of today’s state-of-the-art AI models involves the manual cleaning and labeling of large datasets. This process is laborious, expensive, and among the biggest barriers to more widespread adoption of AI. Plus, as we discussed above, training doesn’t end once a model is deployed. To maintain accuracy, new training data needs to be continually captured, labeled, and fed back into the system. Although techniques like drift detection and active learning can reduce the burden, anecdotal data shows that many companies spend up to 10-15% of revenue on this process – usually not counting core engineering resources – and suggests ongoing development work exceeds typical bug fixes and feature additions.\r\n\r\nSecond: for many tasks, especially those requiring greater cognitive reasoning, humans are often plugged into AI systems in real time. Social media companies, for example, employ thousands of human reviewers to augment AI-based moderation systems. Many autonomous vehicle systems include remote human operators, and most AI-based medical devices interface with physicians as joint decision makers. More and more startups are adopting this approach as the capabilities of modern AI systems are becoming better understood. A number of AI companies that planned to sell pure software products are increasingly bringing a services capability in-house and booking the associated costs.\r\n\r\nThe need for human intervention will likely decline as the performance of AI models improves. It’s unlikely, though, that humans will be cut out of the loop entirely. Many problems – like self-driving cars – are too complex to be fully automated with current-generation AI techniques. Issues of safety, fairness, and trust also demand meaningful human oversight – a fact likely to be enshrined in AI regulations currently under development in the US, EU, and elsewhere.\r\n\r\nEven if we do, eventually, achieve full automation for certain tasks, it’s not clear how much margins will improve as a result. The basic function of an AI application is to process a stream of input data and generate relevant predictions. The cost of operating the system, therefore, is a function of the amount of data being processed. Some data points are handled by humans (relatively expensive), while others are processed automatically by AI models (hopefully less expensive). But every input needs to be handled, one way or the other.\r\n\r\nFor this reason, the two categories of costs we’ve discussed so far – cloud computing and human support – are actually linked. Reducing one tends to drive an increase in the other. Both pieces of the equation can be optimized, but neither one is likely to reach the near-zero cost levels associated with SaaS businesses.\r\n\r\nScaling AI systems can be rockier than expected, because AI lives in the long tail \r\nFor AI companies, knowing when you’ve found product-market fit is just a little bit harder than with traditional software. It’s deceptively easy to think you’ve gotten there – especially after closing 5-10 great customers – only to see the backlog for your ML team start to balloon and customer deployment schedules start to stretch out ominously, drawing resources away from new sales.\r\n\r\nThe culprit, in many situations, is edge cases. Many AI apps have open-ended interfaces and operate on noisy, unstructured data (like images or natural language). Users often lack intuition around the product or, worse, assume it has human/superhuman capabilities. This means edge cases are everywhere: as much as 40-50% of intended functionality for AI products we’ve looked at can reside in the long tail of user intent.\r\n\r\nPut another way, users can – and will – enter just about anything into an AI app.\r\n\r\nHandling this huge state space tends to be an ongoing chore. Since the range of possible input values is so large, each new customer deployment is likely to generate data that has never been seen before. Even customers that appear similar – two auto manufacturers doing defect detection, for example – may require substantially different training data, due to something as simple as the placement of video cameras on their assembly lines.\r\n\r\nOne founder calls this phenomenon the “time cost” of AI products. Her company runs a dedicated period of data collection and model fine-tuning at the start of each new customer engagement. This gives them visibility into the distribution of the customer’s data and eliminates some edge cases prior to deployment. But it also entails a cost: the company’s team and financial resources are tied up until model accuracy reaches an acceptable level. The duration of the training period is also generally unknown, since there are typically few options to generate training data faster… no matter how hard the team works.\r\n\r\nAI startups often end up devoting more time and resources to deploying their products than they expected. Identifying these needs in advance can be difficult since traditional prototyping tools – like mockups, prototypes, or beta tests – tend to cover only the most common paths, not the edge cases. Like traditional software, the process is especially time-consuming with the earliest customer cohorts, but unlike traditional software, it doesn’t necessarily disappear over time.\r\n\r\nThe playbook for defending AI businesses is still being written \r\nGreat software companies are built around strong defensive moats. Some of the best moats are strong forces like network effects, high switching costs, and economies of scale.\r\n\r\nAll of these factors are possible for AI companies, too.  The foundation for defensibility is usually formed, though – especially in the enterprise – by a technically superior product. Being the first to implement a complex piece of software can yield major brand advantages and periods of near-exclusivity.\r\n\r\nIn the AI world, technical differentiation is harder to achieve. New model architectures are being developed mostly in open, academic settings. Reference implementations (pre-trained models) are available from open-source libraries, and model parameters can be optimized automatically. Data is the core of an AI system, but it’s often owned by customers, in the public domain, or over time becomes a commodity. It also has diminishing value as markets mature and shows relatively weak network effects. In some cases, we’ve even seen diseconomies of scale associated with the data feeding AI businesses. As models become more mature – as argued in “The Empty Promise of Data Moats” – each new edge case becomes more and more costly to address, while delivering value to fewer and fewer relevant customers.\r\n\r\nThis does not necessarily mean AI products are less defensible than their pure software counterparts. But the moats for AI companies appear to be shallower than many expected. AI may largely be a pass-through, from a defensibility standpoint, to the underlying product and data.\r\n\r\nBuilding, scaling, and defending great AI companies – practical advice for founders \r\nWe believe the key to long-term success for AI companies is to own the challenges and combine the best of both services and software. In that vein, here are a number of steps founders can take to thrive with new or existing AI applications.\r\n\r\nEliminate model complexity as much as possible. We’ve seen a massive difference in COGS between startups that train a unique model per customer versus those that are able to share a single model (or set of models) among all customers. The “single model” strategy is easier to maintain, faster to roll out to new customers, and supports a simpler, more efficient engineering org. It also tends to reduce data pipeline sprawl and duplicative training runs, which can meaningfully improve cloud infrastructure costs. While there is no silver bullet to reaching this ideal state, one key is to understand as much as possible about your customers – and their data – before agreeing to a deal. Sometimes it’s obvious that a new customer will cause a major fork in your ML engineering efforts. Most of the time, the changes are more subtle, involving only a few unique models or some fine-tuning. Making these judgment calls – trading off long-term economic health versus near-term growth – is one of the most important jobs facing AI founders.\r\n\r\nChoose problem domains carefully – and often narrowly – to reduce data complexity. Automating human labor is a fundamentally hard thing to do. Many companies are finding that the minimum viable task for AI models is narrower than they expected. Rather than offering general text suggestions, for instance, some teams have found success offering short suggestions in email or job postings. Companies working in the CRM space have found highly valuable niches for AI based just around updating records. There is a large class of problems, like these, that are hard for humans to perform but relatively easy for AI. They tend to involve high-scale, low-complexity tasks, such as moderation, data entry/coding, transcription, etc. Focusing on these areas can minimize the challenge of persistent edge cases – in other words, they can simplify the data feeding the AI development process.\r\n\r\nPlan for high variable costs. As a founder, you should have a reliable, intuitive mental framework for your business model. The costs discussed in this post are likely to get better – reduced by some constant – but it would be a mistake to assume they will disappear completely (or to force that unnaturally). Instead, we suggest building a business model and GTM strategy with lower gross margins in mind. Some good advice from founders: Understand deeply the distribution of data feeding your models. Treat model maintenance and human failover as first-order problems. Track down and measure your real variable costs – don’t let them hide in R&D. Make conservative unit economic assumptions in your financial models, especially during a fundraise. Don’t wait for scale, or outside tech advances, to solve the problem.\r\n\r\nEmbrace services. There are huge opportunities to meet the market where it stands. That may mean offering a full-stack translation service rather than translation software or running a taxi service rather than selling self-driving cars. Building hybrid businesses is harder than pure software, but this approach can provide deep insight into customer needs and yield fast-growing, market-defining companies. Services can also be a great tool to kickstart a company’s go-to-market engine – see this post for more on this – especially when selling complex and/or brand new technology. The key is pursue one strategy in a committed way, rather than supporting both software and services customers.\r\n\r\nPlan for change in the tech stack. Modern AI is still in its infancy. The tools that help practitioners do their jobs in an efficient and standardized way are just now being built. Over the next several years, we expect to see widespread availability of tools to automate model training, make inference more efficient, standardize developer workflows, and monitor and secure AI models in production. Cloud computing, in general, is also gaining more attention as a cost issue to be addressed by software companies. Tightly coupling an application to the current way of doing things may lead to an architectural disadvantage in the future.\r\n\r\nBuild defensibility the old-fashioned way. While it’s not clear whether an AI model itself – or the underlying data – will provide a long-term moat, good products and proprietary data almost always builds good businesses. AI gives founders a new angle on old problems. AI techniques, for example, have delivered novel value in the relatively sleepy malware detection market by simply showing better performance. The opportunity to build sticky products and enduring businesses on top of initial, unique product capabilities is evergreen. Interestingly, we’ve also seen several AI companies cement their market position through an effective cloud strategy, similar to the most recent generation of open-source companies.\r\n\r\n* * *\r\n\r\nTo summarize: most AI systems today aren’t quite software, in the traditional sense. And AI businesses, as a result, don’t look exactly like software businesses. They involve ongoing human support and material variable costs. They often don’t scale quite as easily as we’d like. And strong defensibility – critical to the “build once / sell many times” software model – doesn’t seem to come for free.\r\n\r\nThese traits make AI feel, to an extent, like a services business. Put another way: you can replace the services firm, but you can’t (completely) replace the services.\r\n\r\nBelieve it or not, this may be good news. Things like variable costs, scaling dynamics, and defensive moats are ultimately determined by markets – not individual companies. The fact that we’re seeing unfamiliar patterns in the data suggests AI companies are truly something new – pushing into new markets and building massive opportunities. There are already a number of great AI companies who have successfully navigated the idea maze and built products with consistently strong performance.\r\n\r\nAI is still early in the transition from research topic to production technology. It’s easy to forget that AlexNet, which arguably kickstarted the current wave of AI software development, was published less than eight years ago. Intelligent applications are driving the software industry forward, and we’re excited to see where they go next.\r\n\r\n—\r\n\r\nSources: Gross margin estimates for traditional software were based on a selection of companies listed on publiccomps.com; gross margin estimates for services companies were based on 10k filings; and gross margin estimates for AI businesses were based on several interviews with founders of AI startups.', 1, '2022-07-31 12:09:02', ''),
(23, 'new', 'new', 1, '2022-07-31 12:09:02', ''),
(24, 'yeae', 'eedd', 1, '2022-07-31 12:09:02', ''),
(25, 'uu', 'uu', 1, '2022-07-31 12:09:02', ''),
(26, 'dd', 'dddddd', 1, '2022-07-31 12:56:13', ''),
(27, 'gg', 'gg', 1, '2022-07-31 15:16:07', ''),
(29, 'ss', 'ssss', 1, '2022-07-31 16:21:57', ''),
(30, 'uuu', 'uu', 1, '2022-07-31 16:28:15', ''),
(31, 'yy', 'yy', 1, '2022-07-31 17:05:18', 'http://[::1]/Blog_Project(CI-3)/uploads/2021-05-07_(1)6.png'),
(32, 'hi ', 'eeeeeeeeeee', 1, '2022-07-31 18:46:41', 'http://[::1]/Blog_Project(CI-3)/uploads/2021-03-24.png');

-- --------------------------------------------------------

--
-- Table structure for table `users`
--

CREATE TABLE `users` (
  `id` int(255) NOT NULL,
  `uname` varchar(255) NOT NULL,
  `pword` varchar(255) NOT NULL,
  `fname` varchar(255) NOT NULL,
  `lname` varchar(255) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

--
-- Dumping data for table `users`
--

INSERT INTO `users` (`id`, `uname`, `pword`, `fname`, `lname`) VALUES
(1, 'Rohan', '04200420', 'Sk', 'Rohan');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `articles`
--
ALTER TABLE `articles`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `users`
--
ALTER TABLE `users`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `articles`
--
ALTER TABLE `articles`
  MODIFY `id` int(255) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=33;

--
-- AUTO_INCREMENT for table `users`
--
ALTER TABLE `users`
  MODIFY `id` int(255) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=2;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
